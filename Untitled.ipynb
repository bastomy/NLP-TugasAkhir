{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "1  tweet downloaded  2019-05-11 08:15:34\n",
      "2  tweet downloaded  2019-05-11 08:15:25\n",
      "3  tweet downloaded  2019-05-11 08:15:22\n",
      "4  tweet downloaded  2019-05-11 08:15:20\n",
      "5  tweet downloaded  2019-05-11 08:15:19\n",
      "6  tweet downloaded  2019-05-11 08:15:17\n",
      "7  tweet downloaded  2019-05-11 08:14:53\n",
      "8  tweet downloaded  2019-05-11 08:14:52\n",
      "9  tweet downloaded  2019-05-11 08:14:48\n",
      "10  tweet downloaded  2019-05-11 08:14:47\n",
      "11  tweet downloaded  2019-05-11 08:14:16\n",
      "12  tweet downloaded  2019-05-11 08:14:12\n",
      "13  tweet downloaded  2019-05-11 08:13:43\n",
      "14  tweet downloaded  2019-05-11 08:13:31\n",
      "15  tweet downloaded  2019-05-11 08:13:11\n",
      "16  tweet downloaded  2019-05-11 08:13:11\n",
      "17  tweet downloaded  2019-05-11 08:12:59\n",
      "18  tweet downloaded  2019-05-11 08:12:19\n",
      "19  tweet downloaded  2019-05-11 08:12:12\n",
      "20  tweet downloaded  2019-05-11 08:11:58\n",
      "21  tweet downloaded  2019-05-11 08:11:37\n",
      "22  tweet downloaded  2019-05-11 08:11:32\n",
      "23  tweet downloaded  2019-05-11 08:10:49\n",
      "24  tweet downloaded  2019-05-11 08:10:48\n",
      "25  tweet downloaded  2019-05-11 08:10:47\n",
      "26  tweet downloaded  2019-05-11 08:10:32\n",
      "27  tweet downloaded  2019-05-11 08:10:19\n",
      "28  tweet downloaded  2019-05-11 08:10:06\n",
      "29  tweet downloaded  2019-05-11 08:10:05\n",
      "30  tweet downloaded  2019-05-11 08:10:00\n",
      "31  tweet downloaded  2019-05-11 08:09:54\n",
      "32  tweet downloaded  2019-05-11 08:09:44\n",
      "33  tweet downloaded  2019-05-11 08:09:40\n",
      "34  tweet downloaded  2019-05-11 08:09:30\n",
      "35  tweet downloaded  2019-05-11 08:09:25\n",
      "36  tweet downloaded  2019-05-11 08:09:16\n",
      "37  tweet downloaded  2019-05-11 08:09:12\n",
      "38  tweet downloaded  2019-05-11 08:08:53\n",
      "39  tweet downloaded  2019-05-11 08:08:50\n",
      "40  tweet downloaded  2019-05-11 08:08:46\n",
      "41  tweet downloaded  2019-05-11 08:08:42\n",
      "42  tweet downloaded  2019-05-11 08:07:45\n",
      "43  tweet downloaded  2019-05-11 08:07:14\n",
      "44  tweet downloaded  2019-05-11 08:06:45\n",
      "45  tweet downloaded  2019-05-11 08:06:35\n",
      "46  tweet downloaded  2019-05-11 08:06:18\n",
      "47  tweet downloaded  2019-05-11 08:05:53\n",
      "48  tweet downloaded  2019-05-11 08:04:43\n",
      "49  tweet downloaded  2019-05-11 08:04:06\n",
      "50  tweet downloaded  2019-05-11 08:03:44\n",
      "51  tweet downloaded  2019-05-11 08:03:32\n",
      "52  tweet downloaded  2019-05-11 08:03:22\n",
      "53  tweet downloaded  2019-05-11 08:03:14\n",
      "54  tweet downloaded  2019-05-11 08:02:59\n",
      "55  tweet downloaded  2019-05-11 08:02:43\n",
      "56  tweet downloaded  2019-05-11 08:02:31\n",
      "57  tweet downloaded  2019-05-11 08:02:16\n",
      "58  tweet downloaded  2019-05-11 08:02:13\n",
      "59  tweet downloaded  2019-05-11 08:02:06\n",
      "60  tweet downloaded  2019-05-11 08:02:05\n",
      "61  tweet downloaded  2019-05-11 08:01:56\n",
      "62  tweet downloaded  2019-05-11 08:01:28\n",
      "63  tweet downloaded  2019-05-11 08:01:18\n",
      "64  tweet downloaded  2019-05-11 08:01:06\n",
      "65  tweet downloaded  2019-05-11 08:00:37\n",
      "66  tweet downloaded  2019-05-11 08:00:24\n",
      "67  tweet downloaded  2019-05-11 08:00:15\n",
      "68  tweet downloaded  2019-05-11 08:00:07\n",
      "69  tweet downloaded  2019-05-11 07:59:54\n",
      "70  tweet downloaded  2019-05-11 07:59:35\n",
      "71  tweet downloaded  2019-05-11 07:59:22\n",
      "72  tweet downloaded  2019-05-11 07:59:17\n",
      "73  tweet downloaded  2019-05-11 07:58:49\n",
      "74  tweet downloaded  2019-05-11 07:58:25\n",
      "75  tweet downloaded  2019-05-11 07:58:20\n",
      "76  tweet downloaded  2019-05-11 07:58:13\n",
      "77  tweet downloaded  2019-05-11 07:57:19\n",
      "78  tweet downloaded  2019-05-11 07:57:19\n",
      "79  tweet downloaded  2019-05-11 07:57:12\n",
      "80  tweet downloaded  2019-05-11 07:56:45\n",
      "81  tweet downloaded  2019-05-11 07:56:32\n",
      "82  tweet downloaded  2019-05-11 07:56:22\n",
      "83  tweet downloaded  2019-05-11 07:55:38\n",
      "84  tweet downloaded  2019-05-11 07:55:16\n",
      "85  tweet downloaded  2019-05-11 07:54:56\n",
      "86  tweet downloaded  2019-05-11 07:54:31\n",
      "87  tweet downloaded  2019-05-11 07:54:27\n",
      "88  tweet downloaded  2019-05-11 07:53:01\n",
      "89  tweet downloaded  2019-05-11 07:52:18\n",
      "90  tweet downloaded  2019-05-11 07:52:12\n",
      "91  tweet downloaded  2019-05-11 07:51:21\n",
      "92  tweet downloaded  2019-05-11 07:51:07\n",
      "93  tweet downloaded  2019-05-11 07:50:56\n",
      "94  tweet downloaded  2019-05-11 07:50:52\n",
      "95  tweet downloaded  2019-05-11 07:50:32\n",
      "96  tweet downloaded  2019-05-11 07:50:20\n",
      "97  tweet downloaded  2019-05-11 07:50:10\n",
      "98  tweet downloaded  2019-05-11 07:49:59\n",
      "99  tweet downloaded  2019-05-11 07:49:19\n",
      "100  tweet downloaded  2019-05-11 07:49:07\n",
      "successfully\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "\n",
    "class Services:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.consumer_key = 'aqh26LmWvnCwEqoWnBkNDgq3X'\n",
    "        self.consumer_secret = 'WLTGI57tcvei5AwtZNxiyrqDmTqhmVEaeQlXhknzIFZBym58Fv'\n",
    "        self.access_token = '232106297-SLMzoxQqdrOboZlOs8VLShayem1FUr99pGE8Y8Wi'\n",
    "        self.access_token_secret = '8qlseHuNKDsnIVnxuxDZcXfjDepCrWDcp5U1JtZ4PfOU9'\n",
    "        self.auth = tweepy.OAuthHandler(self.consumer_key, self.consumer_secret)\n",
    "        self.auth.set_access_token(self.access_token, self.access_token_secret)\n",
    "        self.api = tweepy.API(self.auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "    def getData(self,parameter):\n",
    "        print(\"starting\")\n",
    "        i = 0\n",
    "        with open('review.csv', 'w', newline='') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            row = [\"ID Tweet\", \"ID User\", \"Screen Name\", \"Tweet\", \"Timestamp\"]\n",
    "            writer.writerow(row)\n",
    "            for post in tweepy.Cursor(self.api.search, q=parameter, tweet_mode='extended').items():\n",
    "                try:\n",
    "                    if (post.retweet_count == 0):\n",
    "                        if i <= 99 :\n",
    "                            row = [post.id_str.encode('utf-8'), post.user.id_str.encode('utf-8'), post.user.screen_name,\n",
    "                                   post.full_text.encode('utf-8'), post.created_at]\n",
    "                            writer.writerow(row)\n",
    "                        else:\n",
    "                            break\n",
    "                        i = i + 1\n",
    "                        print(i, \" tweet downloaded \", post.created_at)\n",
    "                except tweepy.RateLimitError:\n",
    "                    print(\"sleep\")\n",
    "                except tweepy.TweepError as e:\n",
    "                    print('tweepy error')\n",
    "                    print(e.reason)\n",
    "                    continue\n",
    "                except StopIteration:  # stop iteration when last tweet is reached\n",
    "                    print('habis')\n",
    "                    break\n",
    "        csvFile.close()\n",
    "        return True\n",
    "\n",
    "mention = \"@prabowo\"\n",
    "if (Services().getData(mention)):\n",
    "    print(\"successfully\")\n",
    "else:\n",
    "    print(\"failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenisasi(str):\n",
    "    return tknzr.tokenize(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mention_and_link(token):\n",
    "    result = []\n",
    "    for i in token:\n",
    "        if i[:1] != \"@\" and i[:4] != \"http\":\n",
    "            result.append(i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tokenisasi('@sy_haris @AndiArief__ @prabowo UKRI BOCORKAN MENGAPA 01 TETAP DIPAKSAKAN MENANG MESKI HARUS .....??\\n\\n@DivHumas_Polri\\n@Puspen_TNI\\n@tni_ad\\n\\nhttps://t.co/EpnpR2M9ku')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b = remove_mention_and_link(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_symbol(string):\n",
    "    if re.sub(r'[^\\w]', '', string) != '':\n",
    "        return re.sub(r'[^\\w]', '', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "for string in b:\n",
    "    if remove_symbol(string) != None:\n",
    "        c.append(remove_symbol(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UKRI',\n",
       " 'BOCORKAN',\n",
       " 'MENGAPA',\n",
       " '01',\n",
       " 'TETAP',\n",
       " 'DIPAKSAKAN',\n",
       " 'MENANG',\n",
       " 'MESKI',\n",
       " 'HARUS']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
